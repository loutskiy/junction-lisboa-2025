from flask import Flask, request, jsonify
from flask_cors import CORS
import json
import pandas as pd
import numpy as np
import joblib
import re
from sklearn.feature_extraction.text import TfidfVectorizer
import warnings
warnings.filterwarnings('ignore')

app = Flask(__name__)
CORS(app)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏
model = None
feature_names = None
tfidf = None

def rule_based_classifier(text):
    """–ü—Ä–∞–≤–∏–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤"""
    
    text_lower = text.lower()
    
    # –°—á–µ—Ç—á–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
    platform_score = 0
    commercial_score = 0
    free_score = 0
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è platform —Å –≤–µ—Å–∞–º–∏
    platform_keywords = {
        'platform': 3, 'architecture': 2, 'framework': 2, 'infrastructure': 2, 'system': 1,
        'modular': 2, 'scalable': 2, 'extensible': 2, 'api': 2, 'sdk': 2,
        'integration': 1, 'ecosystem': 2, 'foundation': 1, 'base': 1, 'core': 1,
        'cartridge': 2, 'modular cartridges': 4, 'platform architecture': 4,
        'engine': 1, 'interface': 1, 'component': 1, 'module': 1, 'service': 1
    }
    platform_score = sum(weight for word, weight in platform_keywords.items() if word in text_lower)
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è commercial —Å –≤–µ—Å–∞–º–∏
    commercial_keywords = {
        'licensable': 4, 'license': 3, 'licensing': 3, 'commercial': 2, 'market': 1,
        'revenue': 2, 'profit': 2, 'business': 1, 'enterprise': 1, 'industry': 1,
        'commercialization': 4, 'monetization': 3, 'patentable': 4, 'patent': 3,
        'invention': 2, 'novel': 2, 'unique': 1, 'proprietary': 3, 'exclusive': 3,
        'original': 1, 'innovative': 2, 'breakthrough': 3, 'discovery': 2,
        'method': 1, 'process': 1, 'technique': 1, 'approach': 1, 'solution': 1,
        'valuable': 2, 'profitable': 2, 'marketable': 2, 'economic': 1
    }
    commercial_score = sum(weight for word, weight in commercial_keywords.items() if word in text_lower)
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è free —Å –≤–µ—Å–∞–º–∏
    free_keywords = {
        'free': 3, 'open': 2, 'public': 1, 'available': 1, 'accessible': 1,
        'unrestricted': 3, 'unlimited': 3, 'unencumbered': 3, 'clear': 1,
        'unobstructed': 3, 'unimpeded': 3, 'unrestrained': 3, 'unfettered': 3,
        'freetooperate': 4, 'free to operate': 4, 'freedom to operate': 4,
        'unconstrained': 3, 'unlimited use': 3, 'open source': 3, 'public domain': 3
    }
    free_score = sum(weight for word, weight in free_keywords.items() if word in text_lower)
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–ª–∞—Å—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —Å–∫–æ—Ä–∞
    scores = {
        'platform': platform_score,
        'commercial': commercial_score,
        'free': free_score
    }
    
    # –ï—Å–ª–∏ –≤—Å–µ —Å–∫–æ—Ä—ã —Ä–∞–≤–Ω—ã 0, –∏—Å–ø–æ–ª—å–∑—É–µ–º —ç–≤—Ä–∏—Å—Ç–∏–∫—É
    if max(scores.values()) == 0:
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if any(word in text_lower for word in ['technology', 'innovation', 'development', 'research']):
            return 'commercial'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π
        elif any(word in text_lower for word in ['system', 'method', 'approach']):
            return 'platform'  # –ü–ª–∞—Ç—Ñ–æ—Ä–º–∞
        else:
            return 'commercial'  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π
    
    return max(scores, key=scores.get)

def extract_enhanced_features(text):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∏—á–µ–π"""
    
    text_lower = text.lower()
    
    features = {
        # –ë–∞–∑–æ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        'text_length': len(text),
        'word_count': len(text.split()),
        'avg_word_length': np.mean([len(w) for w in text.split()]) if text.split() else 0,
        'unique_word_ratio': len(set(text.split())) / len(text.split()) if text.split() else 0,
        
        # –°–∫–æ—Ä–∏–Ω–≥ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        'platform_score': 0,
        'commercial_score': 0,
        'free_score': 0,
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
        'technical_terms': 0,
        'scientific_terms': 0,
        'business_terms': 0,
        'engineering_terms': 0,
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–Ω—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
        'has_numbers': int(bool(re.search(r'\d+', text))),
        'has_measurements': int(bool(re.search(r'\d+\s*(mg|ml|kg|g|m|cm|mm|nm|Œºm|%)', text))),
        'has_percentages': int('%' in text or 'percent' in text_lower),
        'has_comparisons': int(any(word in text_lower for word in ['better', 'improved', 'enhanced', 'superior', 'advanced', 'increased', 'reduced'])),
        'has_quantifiers': int(any(word in text_lower for word in ['high', 'low', 'large', 'small', 'big', 'tiny', 'massive', 'minimal'])),
        
        # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
        'has_platform_patterns': 0,
        'has_commercial_patterns': 0,
        'has_free_patterns': 0,
        
        # –°–ª–æ–∂–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞
        'complexity_score': 0,
        'technical_density': 0,
        
        # –ù–æ–≤—ã–µ —Ñ–∏—á–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞
        'sentence_count': len([s for s in text.split('.') if s.strip()]),
        'question_marks': text.count('?'),
        'exclamation_marks': text.count('!'),
        'has_capitals': int(any(c.isupper() for c in text)),
        'has_parentheses': int('(' in text and ')' in text),
        'has_quotes': int('"' in text or "'" in text),
        'has_dashes': int('-' in text),
        'has_colons': int(':' in text),
        'has_semicolons': int(';' in text),
    }
    
    # –ü–æ–¥—Å—á–µ—Ç –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ —Å –≤–µ—Å–∞–º–∏
    platform_keywords = {
        'platform': 3, 'architecture': 2, 'framework': 2, 'infrastructure': 2, 'system': 1,
        'modular': 2, 'scalable': 2, 'extensible': 2, 'api': 2, 'sdk': 2,
        'integration': 1, 'ecosystem': 2, 'foundation': 1, 'base': 1, 'core': 1,
        'cartridge': 2, 'modular cartridges': 4, 'platform architecture': 4,
        'engine': 1, 'interface': 1, 'component': 1, 'module': 1, 'service': 1
    }
    features['platform_score'] = sum(weight for word, weight in platform_keywords.items() if word in text_lower)
    
    commercial_keywords = {
        'licensable': 4, 'license': 3, 'licensing': 3, 'commercial': 2, 'market': 1,
        'revenue': 2, 'profit': 2, 'business': 1, 'enterprise': 1, 'industry': 1,
        'commercialization': 4, 'monetization': 3, 'patentable': 4, 'patent': 3,
        'invention': 2, 'novel': 2, 'unique': 1, 'proprietary': 3, 'exclusive': 3,
        'original': 1, 'innovative': 2, 'breakthrough': 3, 'discovery': 2,
        'method': 1, 'process': 1, 'technique': 1, 'approach': 1, 'solution': 1,
        'valuable': 2, 'profitable': 2, 'marketable': 2, 'economic': 1
    }
    features['commercial_score'] = sum(weight for word, weight in commercial_keywords.items() if word in text_lower)
    
    free_keywords = {
        'free': 3, 'open': 2, 'public': 1, 'available': 1, 'accessible': 1,
        'unrestricted': 3, 'unlimited': 3, 'unencumbered': 3, 'clear': 1,
        'unobstructed': 3, 'unimpeded': 3, 'unrestrained': 3, 'unfettered': 3,
        'freetooperate': 4, 'free to operate': 4, 'freedom to operate': 4,
        'unconstrained': 3, 'unlimited use': 3, 'open source': 3, 'public domain': 3
    }
    features['free_score'] = sum(weight for word, weight in free_keywords.items() if word in text_lower)
    
    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã
    technical_words = {
        'algorithm': 2, 'optimization': 2, 'efficiency': 1, 'performance': 1, 'processing': 1,
        'computing': 1, 'analysis': 1, 'synthesis': 1, 'engineering': 1, 'design': 1,
        'implementation': 1, 'development': 1, 'programming': 1, 'coding': 1, 'software': 1,
        'hardware': 1, 'device': 1, 'apparatus': 1, 'machine': 1, 'tool': 1
    }
    features['technical_terms'] = sum(weight for word, weight in technical_words.items() if word in text_lower)
    
    # –ù–∞—É—á–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
    scientific_words = {
        'research': 1, 'study': 1, 'experiment': 1, 'trial': 1, 'test': 1, 'validation': 1,
        'verification': 1, 'hypothesis': 1, 'theory': 1, 'principle': 1, 'concept': 1,
        'discovery': 1, 'finding': 1, 'result': 1, 'conclusion': 1, 'evidence': 1,
        'data': 1, 'analysis': 1, 'statistics': 1, 'measurement': 1, 'observation': 1
    }
    features['scientific_terms'] = sum(weight for word, weight in scientific_words.items() if word in text_lower)
    
    # –ë–∏–∑–Ω–µ—Å —Ç–µ—Ä–º–∏–Ω—ã
    business_words = {
        'market': 1, 'customer': 1, 'user': 1, 'client': 1, 'product': 1, 'service': 1,
        'sales': 1, 'marketing': 1, 'advertising': 1, 'promotion': 1, 'brand': 1,
        'competition': 1, 'competitive': 1, 'advantage': 1, 'value': 1, 'benefit': 1,
        'cost': 1, 'price': 1, 'investment': 1, 'return': 1, 'roi': 1
    }
    features['business_terms'] = sum(weight for word, weight in business_words.items() if word in text_lower)
    
    # –ò–Ω–∂–µ–Ω–µ—Ä–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
    engineering_words = {
        'engineering': 1, 'design': 1, 'construction': 1, 'manufacturing': 1, 'production': 1,
        'assembly': 1, 'fabrication': 1, 'building': 1, 'creating': 1, 'making': 1,
        'developing': 1, 'constructing': 1, 'building': 1, 'creating': 1
    }
    features['engineering_terms'] = sum(weight for word, weight in engineering_words.items() if word in text_lower)
    
    # –°–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    features['has_platform_patterns'] = int(any(phrase in text_lower for phrase in [
        'platform architecture', 'modular cartridges', 'scalable system', 'extensible framework',
        'api platform', 'sdk framework', 'integration platform'
    ]))
    
    features['has_commercial_patterns'] = int(any(phrase in text_lower for phrase in [
        'commercial value', 'market opportunity', 'revenue potential', 'business model',
        'licensing opportunity', 'patent application', 'commercialization strategy'
    ]))
    
    features['has_free_patterns'] = int(any(phrase in text_lower for phrase in [
        'free to operate', 'freedom to operate', 'unrestricted use', 'open source',
        'public domain', 'unlimited access', 'clear path'
    ]))
    
    # –°–ª–æ–∂–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞
    features['complexity_score'] = len([w for w in text.split() if len(w) > 8])
    features['technical_density'] = features['technical_terms'] / max(features['word_count'], 1)
    
    return features

def extract_features_from_idea(idea_text, evidence_data=None):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ñ–∏—á–µ–π –∏–∑ –∏–¥–µ–∏"""
    
    # –ë–∞–∑–æ–≤—ã–µ —Ñ–∏—á–∏
    features = {
        'evidence_count': 0,
        'is_negative': 0,
        
        # Market features
        'max_importance_score': 0.0,
        'avg_importance_score': 0.0,
        'market_evidence_count': 0,
        'has_product_launch': 0,
        'has_ma': 0,
        'has_partnership': 0,
        'has_funding': 0,
        
        # Trial features
        'max_maturity_score': 0.0,
        'avg_maturity_score': 0.0,
        'trial_evidence_count': 0,
        'has_completed_trial': 0,
        'has_phase3_trial': 0,
        'has_terminated_trial': 0,
        
        # Other evidence counts
        'patent_count': 0,
        'paper_count': 0,
        'disclosure_count': 0,
    }
    
    # –î–æ–±–∞–≤–ª—è–µ–º —É–ª—É—á—à–µ–Ω–Ω—ã–µ —Ñ–∏—á–∏
    enhanced_features = extract_enhanced_features(idea_text)
    features.update(enhanced_features)
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º evidence –µ—Å–ª–∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ
    if evidence_data:
        features['evidence_count'] = len(evidence_data)
        
        market_scores = []
        trial_scores = []
        
        for ev in evidence_data:
            if ev.get('type') == 'market' and 'importance_score' in ev.get('meta', {}):
                features['market_evidence_count'] += 1
                market_scores.append(ev['meta']['importance_score'])
                
                # –¢–∏–ø—ã —Å–æ–±—ã—Ç–∏–π
                event_type = ev['meta'].get('type')
                if event_type == 'Product launch':
                    features['has_product_launch'] = 1
                elif event_type == 'M&A':
                    features['has_ma'] = 1
                elif event_type == 'Partnership':
                    features['has_partnership'] = 1
                elif event_type == 'Funding':
                    features['has_funding'] = 1
                    
            elif ev.get('type') == 'trial' and 'maturity_score' in ev.get('meta', {}):
                features['trial_evidence_count'] += 1
                trial_scores.append(ev['meta']['maturity_score'])
                
                # –°—Ç–∞—Ç—É—Å—ã –∏ —Ñ–∞–∑—ã
                status = ev['meta'].get('status')
                phase = ev['meta'].get('phase')
                
                if status == 'Completed':
                    features['has_completed_trial'] = 1
                if phase == 'Phase 3':
                    features['has_phase3_trial'] = 1
                if status == 'Terminated':
                    features['has_terminated_trial'] = 1
                    
            elif ev.get('type') == 'patent':
                features['patent_count'] += 1
            elif ev.get('type') == 'paper':
                features['paper_count'] += 1
            elif ev.get('type') == 'disclosure':
                features['disclosure_count'] += 1
        
        # –í—ã—á–∏—Å–ª—è–µ–º –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–∫–æ—Ä—ã
        if market_scores:
            features['max_importance_score'] = max(market_scores)
            features['avg_importance_score'] = np.mean(market_scores)
        if trial_scores:
            features['max_maturity_score'] = max(trial_scores)
            features['avg_maturity_score'] = np.mean(trial_scores)
    
    return features

def load_model():
    """–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏"""
    global model, feature_names, tfidf
    
    if model is None:
        print("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏...")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        model = joblib.load('final_technology_evaluator.joblib')
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏—è —Ñ–∏—á–µ–π
        with open('final_technology_evaluator_features.json', 'r') as f:
            feature_names = json.load(f)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º TF-IDF
        tfidf = joblib.load('final_technology_evaluator_tfidf.joblib')
        
        print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")

@app.route('/health', methods=['GET'])
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è API"""
    return jsonify({
        'status': 'healthy',
        'message': 'Technology Evaluator API is running',
        'model_loaded': model is not None
    })

@app.route('/readiness', methods=['GET'])
def readiness_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ API"""
    if model is None:
        return jsonify({
            'status': 'not_ready',
            'message': 'Model not loaded'
        }), 503
    
    return jsonify({
        'status': 'ready',
        'message': 'API is ready to process requests'
    }), 200

@app.route('/evaluate', methods=['POST'])
def evaluate_idea():
    """–û—Ü–µ–Ω–∫–∞ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–π –∏–¥–µ–∏"""
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
    load_model()
    
    try:
        data = request.get_json()
        
        if not data or 'idea_text' not in data:
            return jsonify({
                'error': 'Missing required field: idea_text'
            }), 400
        
        idea_text = data['idea_text']
        evidence_data = data.get('evidence', [])
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏—á–∏
        features = extract_features_from_idea(idea_text, evidence_data)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ DataFrame
        X_df = pd.DataFrame([features])
        
        # –î–æ–±–∞–≤–ª—è–µ–º TF-IDF —Ñ–∏—á–∏
        tfidf_features = tfidf.transform([idea_text])
        tfidf_df = pd.DataFrame(
            tfidf_features.toarray(),
            columns=[f'tfidf_{i}' for i in range(tfidf_features.shape[1])]
        )
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ñ–∏—á–∏
        X_combined = pd.concat([X_df, tfidf_df], axis=1)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        ml_prediction = model.predict(X_combined)[0]
        ml_probabilities = model.predict_proba(X_combined)[0]
        ml_confidence = np.max(ml_probabilities)
        
        # –ü—Ä–∞–≤–∏–ª–∞
        rule_prediction = rule_based_classifier(idea_text)
        
        # –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥
        if ml_confidence > 0.7:  # –í—ã—Å–æ–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å ML –º–æ–¥–µ–ª–∏
            hybrid_prediction = ml_prediction
            method = 'ml_high_confidence'
        elif ml_confidence > 0.4:  # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –≤–∑–≤–µ—à–µ–Ω–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ
            if rule_prediction == ml_prediction:
                hybrid_prediction = ml_prediction
                method = 'ml_rule_agreement'
            else:
                hybrid_prediction = ml_prediction
                method = 'ml_medium_confidence'
        else:  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å - –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª–∞
            hybrid_prediction = rule_prediction
            method = 'rule_based'
        
        # –ê–Ω–∞–ª–∏–∑ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤
        evidence_analysis = analyze_evidence(evidence_data)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –ø–æ–¥—Ä–æ–±–Ω—ã–π –æ—Ç–≤–µ—Ç
        response = {
            'idea_text': idea_text,
            'analysis_summary': {
                'prediction': hybrid_prediction,
                'confidence': float(ml_confidence),
                'method': method,
                'evidence_count': evidence_analysis['count'],
                'evidence_types': evidence_analysis['types'],
                'insights': evidence_analysis['insights']
            },
            'predictions': {
                'ml_model': {
                    'prediction': ml_prediction,
                    'confidence': float(ml_confidence),
                    'probabilities': {
                        'commercial': float(ml_probabilities[0]),
                        'free': float(ml_probabilities[1]),
                        'none': float(ml_probabilities[2]),
                        'platform': float(ml_probabilities[3])
                    }
                },
                'rule_based': {
                    'prediction': rule_prediction
                },
                'hybrid': {
                    'prediction': hybrid_prediction,
                    'method': method,
                    'confidence_level': get_confidence_level(features)
                }
            },
            'detailed_features': {
                'text_analysis': {
                    'text_length': features['text_length'],
                    'word_count': features['word_count'],
                    'avg_word_length': features['avg_word_length'],
                    'unique_word_ratio': features['unique_word_ratio'],
                    'sentence_count': features['sentence_count'],
                    'complexity_score': features['complexity_score']
                },
                'keyword_scores': {
                    'platform_score': features['platform_score'],
                    'commercial_score': features['commercial_score'],
                    'free_score': features['free_score'],
                    'technical_terms': features['technical_terms'],
                    'scientific_terms': features['scientific_terms'],
                    'business_terms': features['business_terms']
                },
                'evidence_analysis': {
                    'total_evidence': features['evidence_count'],
                    'market_signals': features['market_evidence_count'],
                    'clinical_trials': features['trial_evidence_count'],
                    'patents': features['patent_count'],
                    'papers': features['paper_count'],
                    'disclosures': features['disclosure_count']
                },
                'market_indicators': {
                    'max_importance_score': features['max_importance_score'],
                    'avg_importance_score': features['avg_importance_score'],
                    'product_launches': features['has_product_launch'],
                    'mergers_acquisitions': features['has_ma'],
                    'partnerships': features['has_partnership'],
                    'funding_activity': features['has_funding']
                },
                'clinical_indicators': {
                    'max_maturity_score': features['max_maturity_score'],
                    'avg_maturity_score': features['avg_maturity_score'],
                    'completed_trials': features['has_completed_trial'],
                    'phase3_trials': features['has_phase3_trial'],
                    'terminated_trials': features['has_terminated_trial']
                },
                'pattern_analysis': {
                    'has_platform_patterns': features['has_platform_patterns'],
                    'has_commercial_patterns': features['has_commercial_patterns'],
                    'has_free_patterns': features['has_free_patterns'],
                    'has_numbers': features['has_numbers'],
                    'has_measurements': features['has_measurements'],
                    'has_comparisons': features['has_comparisons']
                }
            },
            'recommendations': generate_recommendations(hybrid_prediction, features, evidence_data),
            'metadata': {
                'timestamp': pd.Timestamp.now().isoformat(),
                'model_version': 'final_technology_evaluator',
                'api_version': '1.0.0',
                'processing_time_ms': 0  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏
            }
        }
        
        return jsonify(response)
        
    except Exception as e:
        return jsonify({
            'error': f'Internal server error: {str(e)}'
        }), 500

def generate_recommendations(prediction, features, evidence_data):
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–æ–¥—Ä–æ–±–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
    
    recommendations = []
    
    # –ê–Ω–∞–ª–∏–∑ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤
    evidence_analysis = analyze_evidence(evidence_data)
    
    if prediction == 'commercial':
        # –û—Å–Ω–æ–≤–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
        recommendations.append({
            'type': 'commercial_opportunity',
            'priority': 'high',
            'title': '–ö–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª',
            'message': '–≠—Ç–∞ –∏–¥–µ—è –∏–º–µ–µ—Ç –≤—ã—Å–æ–∫–∏–π –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è –ª–∏—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–∏—è –∏ –º–æ–Ω–µ—Ç–∏–∑–∞—Ü–∏–∏',
            'confidence': get_confidence_level(features),
            'actions': [
                '–ü—Ä–æ–≤–µ–¥–∏—Ç–µ –ø–∞—Ç–µ–Ω—Ç–Ω—ã–π –ø–æ–∏—Å–∫ –∏ –∞–Ω–∞–ª–∏–∑ —Å–≤–æ–±–æ–¥—ã –¥–µ–π—Å—Ç–≤–∏–π (FTO)',
                '–û—Ü–µ–Ω–∏—Ç–µ —Ä—ã–Ω–æ—á–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–Ω—É—é —Å—Ä–µ–¥—É',
                '–†–∞–∑—Ä–∞–±–æ—Ç–∞–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ª–∏—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–∏—è',
                '–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–æ —Å –∫—Ä—É–ø–Ω—ã–º–∏ –∫–æ–º–ø–∞–Ω–∏—è–º–∏',
                '–ü–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –±–∏–∑–Ω–µ—Å-–ø–ª–∞–Ω –∫–æ–º–º–µ—Ä—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏'
            ],
            'timeline': '3-6 –º–µ—Å—è—Ü–µ–≤',
            'investment': '–°—Ä–µ–¥–Ω–∏–π-–≤—ã—Å–æ–∫–∏–π',
            'roi_potential': '–í—ã—Å–æ–∫–∏–π'
        })
        
        # –†—ã–Ω–æ—á–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
        if features['market_evidence_count'] > 0:
            recommendations.append({
                'type': 'market_analysis',
                'priority': 'high',
                'title': '–†—ã–Ω–æ—á–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏',
                'message': f'–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {features["market_evidence_count"]} —Ä—ã–Ω–æ—á–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤',
                'details': {
                    'product_launches': features['has_product_launch'],
                    'mergers_acquisitions': features['has_ma'],
                    'partnerships': features['has_partnership'],
                    'funding_rounds': features['has_funding'],
                    'market_importance_score': features['max_importance_score']
                },
                'actions': [
                    '–ò–∑—É—á–∏—Ç–µ —É—Å–ø–µ—à–Ω—ã–µ –∫–µ–π—Å—ã –∑–∞–ø—É—Å–∫–∞ –ø—Ä–æ–¥—É–∫—Ç–æ–≤',
                    '–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ M&A –≤ –æ—Ç—Ä–∞—Å–ª–∏',
                    '–û—Ü–µ–Ω–∏—Ç–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–∞',
                    '–ò—Å—Å–ª–µ–¥—É–π—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏—è'
                ]
            })
        
        # –ö–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—ã—Ç–∞–Ω–∏—è
        if features['trial_evidence_count'] > 0:
            recommendations.append({
                'type': 'clinical_development',
                'priority': 'medium',
                'title': '–ö–ª–∏–Ω–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ',
                'message': f'–ù–∞–π–¥–µ–Ω–æ {features["trial_evidence_count"]} —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏—Ö –∏—Å–ø—ã—Ç–∞–Ω–∏–π',
                'details': {
                    'maturity_score': features['max_maturity_score'],
                    'completed_trials': features['has_completed_trial'],
                    'phase3_trials': features['has_phase3_trial'],
                    'terminated_trials': features['has_terminated_trial']
                },
                'actions': [
                    '–ò–∑—É—á–∏—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—ã—Ö –∏—Å–ø—ã—Ç–∞–Ω–∏–π',
                    '–û—Ü–µ–Ω–∏—Ç–µ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è',
                    '–ü–ª–∞–Ω–∏—Ä—É–π—Ç–µ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è',
                    '–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ —Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç–≤–æ —Å –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–º–∏ —Ü–µ–Ω—Ç—Ä–∞–º–∏'
                ]
            })
        
        # –ü–∞—Ç–µ–Ω—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è
        if features['patent_count'] > 0:
            recommendations.append({
                'type': 'patent_strategy',
                'priority': 'high',
                'title': '–ü–∞—Ç–µ–Ω—Ç–Ω–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—è',
                'message': f'–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {features["patent_count"]} —Å–≤—è–∑–∞–Ω–Ω—ã—Ö –ø–∞—Ç–µ–Ω—Ç–æ–≤',
                'actions': [
                    '–ü—Ä–æ–≤–µ–¥–∏—Ç–µ –ø–∞—Ç–µ–Ω—Ç–Ω—ã–π –ª–∞–Ω–¥—à–∞—Ñ—Ç-–∞–Ω–∞–ª–∏–∑',
                    '–û—Ü–µ–Ω–∏—Ç–µ —Å–≤–æ–±–æ–¥—É –¥–µ–π—Å—Ç–≤–∏–π (Freedom to Operate)',
                    '–†–∞–∑—Ä–∞–±–æ—Ç–∞–π—Ç–µ —Å—Ç—Ä–∞—Ç–µ–≥–∏—é –ø–∞—Ç–µ–Ω—Ç–æ–≤–∞–Ω–∏—è',
                    '–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ª–∏—Ü–µ–Ω–∑–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –ø–∞—Ç–µ–Ω—Ç–æ–≤'
                ]
            })
    
    elif prediction == 'platform':
        recommendations.append({
            'type': 'platform_development',
            'priority': 'medium',
            'title': '–ü–ª–∞—Ç—Ñ–æ—Ä–º–µ–Ω–Ω–∞—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞',
            'message': '–≠—Ç–∞ –∏–¥–µ—è –∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥—É–ª—å–Ω–æ–π –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã',
            'confidence': get_confidence_level(features),
            'actions': [
                '–°–ø—Ä–æ–µ–∫—Ç–∏—Ä—É–π—Ç–µ –º–æ–¥—É–ª—å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É —Å —á–µ—Ç–∫–∏–º–∏ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞–º–∏',
                '–†–∞–∑—Ä–∞–±–æ—Ç–∞–π—Ç–µ API –∏ SDK –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤',
                '–°–æ–∑–¥–∞–π—Ç–µ —ç–∫–æ—Å–∏—Å—Ç–µ–º—É –ø–ª–∞–≥–∏–Ω–æ–≤ –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π',
                '–ü–ª–∞–Ω–∏—Ä—É–π—Ç–µ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ–µ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ',
                '–û–±–µ—Å–ø–µ—á—å—Ç–µ –æ–±—Ä–∞—Ç–Ω—É—é —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –≤–µ—Ä—Å–∏–π'
            ],
            'timeline': '6-12 –º–µ—Å—è—Ü–µ–≤',
            'investment': '–°—Ä–µ–¥–Ω–∏–π',
            'roi_potential': '–°—Ä–µ–¥–Ω–∏–π-–≤—ã—Å–æ–∫–∏–π'
        })
        
        # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞
        recommendations.append({
            'type': 'technical_architecture',
            'priority': 'high',
            'title': '–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞',
            'message': '–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–º—É –¥–∏–∑–∞–π–Ω—É –ø–ª–∞—Ç—Ñ–æ—Ä–º—ã',
            'actions': [
                '–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–∏–∫—Ä–æ—Å–µ—Ä–≤–∏—Å–Ω—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É',
                '–†–µ–∞–ª–∏–∑—É–π—Ç–µ API-first –ø–æ–¥—Ö–æ–¥',
                '–û–±–µ—Å–ø–µ—á—å—Ç–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å –∏ –∞—É—Ç–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é',
                '–î–æ–±–∞–≤—å—Ç–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫—É',
                '–°–æ–∑–¥–∞–π—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤'
            ]
        })
    
    elif prediction == 'free':
        recommendations.append({
            'type': 'open_source',
            'priority': 'low',
            'title': '–û—Ç–∫—Ä—ã—Ç–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ',
            'message': '–≠—Ç–∞ –∏–¥–µ—è –ª—É—á—à–µ –≤—Å–µ–≥–æ –ø–æ–¥—Ö–æ–¥–∏—Ç –¥–ª—è –æ—Ç–∫—Ä—ã—Ç–æ–≥–æ —Ä–∞–∑–≤–∏—Ç–∏—è –∏ –ø—É–±–ª–∏—á–Ω–æ–≥–æ –¥–æ—Å—Ç—É–ø–∞',
            'confidence': get_confidence_level(features),
            'actions': [
                '–í—ã–±–µ—Ä–∏—Ç–µ –ø–æ–¥—Ö–æ–¥—è—â—É—é open source –ª–∏—Ü–µ–Ω–∑–∏—é (MIT, Apache 2.0, GPL)',
                '–°–æ–∑–¥–∞–π—Ç–µ –∞–∫—Ç–∏–≤–Ω–æ–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–æ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤',
                '–û–±–µ—Å–ø–µ—á—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –∏ –ø—Ä–∏–º–µ—Ä—ã',
                '–ù–∞—Å—Ç—Ä–æ–π—Ç–µ CI/CD –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è',
                '–ü–ª–∞–Ω–∏—Ä—É–π—Ç–µ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ —Ä–µ–ª–∏–∑—ã –∏ –æ–±—Ä–∞—Ç–Ω—É—é —Å–≤—è–∑—å'
            ],
            'timeline': '1-3 –º–µ—Å—è—Ü–∞',
            'investment': '–ù–∏–∑–∫–∏–π',
            'roi_potential': '–ù–∏–∑–∫–∏–π-—Å—Ä–µ–¥–Ω–∏–π'
        })
        
        # –°–æ–æ–±—â–µ—Å—Ç–≤–æ –∏ —ç–∫–æ—Å–∏—Å—Ç–µ–º–∞
        recommendations.append({
            'type': 'community_building',
            'priority': 'medium',
            'title': '–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞',
            'message': '–°—Ç—Ä–∞—Ç–µ–≥–∏—è —Å–æ–∑–¥–∞–Ω–∏—è –∞–∫—Ç–∏–≤–Ω–æ–≥–æ —Å–æ–æ–±—â–µ—Å—Ç–≤–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π',
            'actions': [
                '–°–æ–∑–¥–∞–π—Ç–µ GitHub —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å —á–µ—Ç–∫–∏–º README',
                '–ù–∞—Å—Ç—Ä–æ–π—Ç–µ issue tracker –∏ pull request –ø—Ä–æ—Ü–µ—Å—Å',
                '–û—Ä–≥–∞–Ω–∏–∑—É–π—Ç–µ —Ä–µ–≥—É–ª—è—Ä–Ω—ã–µ –º–∏—Ç–∞–ø—ã –∏ –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏–∏',
                '–°–æ–∑–¥–∞–π—Ç–µ —Ñ–æ—Ä—É–º –∏–ª–∏ Discord —Å–µ—Ä–≤–µ—Ä',
                '–ü—Ä–∏–≤–ª–µ–∫–∞–π—Ç–µ –∫–æ–Ω—Ç—Ä–∏–±—å—é—Ç–æ—Ä–æ–≤ —á–µ—Ä–µ–∑ hackathons'
            ]
        })
    
    else:  # none
        recommendations.append({
            'type': 'not_recommended',
            'priority': 'low',
            'title': '–ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è',
            'message': '–≠—Ç–∞ –∏–¥–µ—è –Ω–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è –≤ —Ç–µ–∫—É—â–µ–º –≤–∏–¥–µ',
            'confidence': get_confidence_level(features),
            'reasons': get_rejection_reasons(features),
            'actions': [
                '–ü–µ—Ä–µ—Å–º–æ—Ç—Ä–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω—É—é –∫–æ–Ω—Ü–µ–ø—Ü–∏—é –∏ —Ü–µ–Ω–Ω–æ—Å—Ç–Ω–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ',
                '–ò–∑—É—á–∏—Ç–µ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø–æ–¥—Ö–æ–¥—ã',
                '–ü—Ä–æ–≤–µ–¥–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ —Ä—ã–Ω–∫–∞',
                '–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–∏–≤–æ—Ç –≤ –¥—Ä—É–≥—É—é –æ–±–ª–∞—Å—Ç—å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è',
                '–ü–æ–ª—É—á–∏—Ç–µ —ç–∫—Å–ø–µ—Ä—Ç–Ω—É—é –æ—Ü–µ–Ω–∫—É –æ—Ç –æ—Ç—Ä–∞—Å–ª–µ–≤—ã—Ö —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–æ–≤'
            ],
            'timeline': '1-3 –º–µ—Å—è—Ü–∞',
            'investment': '–ù–∏–∑–∫–∏–π',
            'roi_potential': '–ù–∏–∑–∫–∏–π'
        })
    
    # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    recommendations.append({
        'type': 'general_advice',
        'priority': 'medium',
        'title': '–û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏',
        'message': '–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Å–æ–≤–µ—Ç—ã –¥–ª—è —É—Å–ø–µ—à–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏',
        'actions': [
            '–ü—Ä–æ–≤–µ–¥–∏—Ç–µ –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤',
            '–ò–∑—É—á–∏—Ç–µ —Ä–µ–≥—É–ª—è—Ç–æ—Ä–Ω—ã–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤ –≤–∞—à–µ–π —é—Ä–∏—Å–¥–∏–∫—Ü–∏–∏',
            '–û—Ü–µ–Ω–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —Ä–µ—Å—É—Ä—Å—ã –∏ –∫–æ–º–∞–Ω–¥—É',
            '–†–∞–∑—Ä–∞–±–æ—Ç–∞–π—Ç–µ –ø–ª–∞–Ω –∑–∞—â–∏—Ç—ã –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏',
            '–°–æ–∑–¥–∞–π—Ç–µ MVP –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏'
        ]
    })
    
    return recommendations

def analyze_evidence(evidence_data):
    """–ê–Ω–∞–ª–∏–∑ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤ –∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏–Ω—Å–∞–π—Ç–æ–≤"""
    
    if not evidence_data:
        return {'count': 0, 'types': [], 'insights': []}
    
    evidence_types = {}
    insights = []
    
    for evidence in evidence_data:
        evidence_type = evidence.get('type', 'unknown')
        evidence_types[evidence_type] = evidence_types.get(evidence_type, 0) + 1
        
        # –ê–Ω–∞–ª–∏–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        meta = evidence.get('meta', {})
        
        if evidence_type == 'market':
            if meta.get('type') == 'Product launch':
                insights.append('–û–±–Ω–∞—Ä—É–∂–µ–Ω –∑–∞–ø—É—Å–∫ –ø—Ä–æ–¥—É–∫—Ç–∞ –≤ —Å–≤—è–∑–∞–Ω–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏')
            elif meta.get('type') == 'M&A':
                insights.append('–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Å–ª–∏—è–Ω–∏–π –∏ –ø–æ–≥–ª–æ—â–µ–Ω–∏–π –≤ –æ—Ç—Ä–∞—Å–ª–∏')
            elif meta.get('type') == 'Funding':
                insights.append('–ò–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –≤ —Å–µ–∫—Ç–æ—Ä–µ')
        
        elif evidence_type == 'trial':
            if meta.get('status') == 'Completed':
                insights.append('–ó–∞–≤–µ—Ä—à–µ–Ω–Ω—ã–µ –∫–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—ã—Ç–∞–Ω–∏—è')
            elif meta.get('phase') == 'Phase 3':
                insights.append('–ö–ª–∏–Ω–∏—á–µ—Å–∫–∏–µ –∏—Å–ø—ã—Ç–∞–Ω–∏—è —Ñ–∞–∑—ã 3')
        
        elif evidence_type == 'patent':
            insights.append('–°—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø–∞—Ç–µ–Ω—Ç—ã –≤ –æ–±–ª–∞—Å—Ç–∏')
        
        elif evidence_type == 'paper':
            insights.append('–ù–∞—É—á–Ω—ã–µ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ –ø–æ —Ç–µ–º–µ')
    
    return {
        'count': len(evidence_data),
        'types': evidence_types,
        'insights': insights
    }

def get_confidence_level(features):
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —É—Ä–æ–≤–Ω—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∏—á–µ–π"""
    
    confidence_score = 0
    
    # –ë–∞–∑–æ–≤—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    if features['commercial_score'] > 5:
        confidence_score += 2
    if features['platform_score'] > 5:
        confidence_score += 2
    if features['free_score'] > 5:
        confidence_score += 2
    
    # –î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞
    if features['evidence_count'] > 0:
        confidence_score += 1
    if features['market_evidence_count'] > 0:
        confidence_score += 1
    if features['trial_evidence_count'] > 0:
        confidence_score += 1
    
    # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã
    if features['technical_terms'] > 3:
        confidence_score += 1
    if features['has_commercial_patterns']:
        confidence_score += 1
    if features['has_platform_patterns']:
        confidence_score += 1
    if features['has_free_patterns']:
        confidence_score += 1
    
    if confidence_score >= 6:
        return 'high'
    elif confidence_score >= 3:
        return 'medium'
    else:
        return 'low'

def get_rejection_reasons(features):
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏—á–∏–Ω –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è –∏–¥–µ–∏"""
    
    reasons = []
    
    if features['commercial_score'] < 2 and features['platform_score'] < 2 and features['free_score'] < 2:
        reasons.append('–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏')
    
    if features['technical_terms'] < 2:
        reasons.append('–ù–∏–∑–∫–∞—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å')
    
    if features['evidence_count'] == 0:
        reasons.append('–û—Ç—Å—É—Ç—Å—Ç–≤–∏–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞—é—â–∏—Ö –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤')
    
    if features['text_length'] < 50:
        reasons.append('–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–µ—Ç–∞–ª—å–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ')
    
    if features['word_count'] < 10:
        reasons.append('–°–ª–∏—à–∫–æ–º –∫—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ')
    
    return reasons

@app.route('/batch_evaluate', methods=['POST'])
def batch_evaluate():
    """–ü–∞–∫–µ—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∏–¥–µ–π"""
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞
    load_model()
    
    try:
        data = request.get_json()
        
        if not data or 'ideas' not in data:
            return jsonify({
                'error': 'Missing required field: ideas'
            }), 400
        
        ideas = data['ideas']
        results = []
        
        for i, idea_data in enumerate(ideas):
            idea_text = idea_data.get('idea_text', '')
            evidence_data = idea_data.get('evidence', [])
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∏—á–∏
            features = extract_features_from_idea(idea_text, evidence_data)
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ DataFrame
            X_df = pd.DataFrame([features])
            
            # –î–æ–±–∞–≤–ª—è–µ–º TF-IDF —Ñ–∏—á–∏
            tfidf_features = tfidf.transform([idea_text])
            tfidf_df = pd.DataFrame(
                tfidf_features.toarray(),
                columns=[f'tfidf_{i}' for i in range(tfidf_features.shape[1])]
            )
            
            # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ñ–∏—á–∏
            X_combined = pd.concat([X_df, tfidf_df], axis=1)
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            ml_prediction = model.predict(X_combined)[0]
            ml_probabilities = model.predict_proba(X_combined)[0]
            ml_confidence = np.max(ml_probabilities)
            
            # –ü—Ä–∞–≤–∏–ª–∞
            rule_prediction = rule_based_classifier(idea_text)
            
            # –ì–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–¥—Ö–æ–¥
            if ml_confidence > 0.7:
                hybrid_prediction = ml_prediction
                method = 'ml_high_confidence'
            elif ml_confidence > 0.4:
                if rule_prediction == ml_prediction:
                    hybrid_prediction = ml_prediction
                    method = 'ml_rule_agreement'
                else:
                    hybrid_prediction = ml_prediction
                    method = 'ml_medium_confidence'
            else:
                hybrid_prediction = rule_prediction
                method = 'rule_based'
            
            results.append({
                'id': i,
                'idea_text': idea_text,
                'prediction': hybrid_prediction,
                'confidence': float(ml_confidence),
                'method': method
            })
        
        return jsonify({
            'results': results,
            'total_processed': len(results)
        })
        
    except Exception as e:
        return jsonify({
            'error': f'Internal server error: {str(e)}'
        }), 500

if __name__ == '__main__':
    print("üöÄ –ó–∞–ø—É—Å–∫ Technology Evaluator API...")
    print("=" * 50)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
    load_model()
    
    print("üåê API –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É: http://localhost:5001")
    print("üìö –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è API:")
    print("  GET  /health - –ø—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è")
    print("  GET  /readiness - –ø—Ä–æ–≤–µ—Ä–∫–∞ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏")
    print("  POST /evaluate - –æ—Ü–µ–Ω–∫–∞ –æ–¥–Ω–æ–π –∏–¥–µ–∏")
    print("  POST /batch_evaluate - –ø–∞–∫–µ—Ç–Ω–∞—è –æ—Ü–µ–Ω–∫–∞")
    
    app.run(host='0.0.0.0', port=5001, debug=True)
